{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM94M14Oe4bq",
        "outputId": "9e60939d-a576-4d16-ece1-c90fd9bb5f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.00MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2062, Accuracy: 0.9848, F1: 0.9847, Time: 16.50s\n",
            "Epoch 2: Train Loss: 0.0786, Accuracy: 0.9870, F1: 0.9868, Time: 15.95s\n",
            "Epoch 3: Train Loss: 0.0589, Accuracy: 0.9911, F1: 0.9910, Time: 16.31s\n",
            "Epoch 4: Train Loss: 0.0478, Accuracy: 0.9898, F1: 0.9897, Time: 16.40s\n",
            "Epoch 5: Train Loss: 0.0402, Accuracy: 0.9918, F1: 0.9917, Time: 15.23s\n",
            "Epoch 6: Train Loss: 0.0337, Accuracy: 0.9909, F1: 0.9908, Time: 15.27s\n",
            "Epoch 7: Train Loss: 0.0306, Accuracy: 0.9923, F1: 0.9922, Time: 15.36s\n",
            "Epoch 8: Train Loss: 0.0261, Accuracy: 0.9923, F1: 0.9922, Time: 15.28s\n",
            "Epoch 9: Train Loss: 0.0240, Accuracy: 0.9905, F1: 0.9904, Time: 15.46s\n",
            "Epoch 10: Train Loss: 0.0229, Accuracy: 0.9927, F1: 0.9926, Time: 15.05s\n",
            "Average epoch time: 15.68s\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation des données\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Chargement MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Architecture CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64*7*7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64*7*7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Entraînement et évaluation\n",
        "def train_cnn(epochs=10):\n",
        "    model = CNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_times = []\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_time = time.time() - start_time\n",
        "        train_times.append(train_time)\n",
        "\n",
        "        # Évaluation\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images.to(device))\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_targets, all_preds)\n",
        "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Time: {train_time:.2f}s')\n",
        "\n",
        "    avg_time = sum(train_times)/len(train_times)\n",
        "    print(f'Average epoch time: {avg_time:.2f}s')\n",
        "    return model\n",
        "\n",
        "# Exécution\n",
        "cnn_model = train_cnn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture MiniFasterRCNN\n",
        "class MiniFasterRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32*7*7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Entraînement spécifique RCNN\n",
        "def train_frcnn(epochs=5):\n",
        "    model = MiniFasterRCNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Adaptation des données pour RCNN\n",
        "    def collate_fn(batch):\n",
        "        images = torch.stack([item[0] for item in batch])\n",
        "        targets = [{'labels': torch.tensor(item[1], dtype=torch.int64)} for item in batch]\n",
        "        return images, targets\n",
        "\n",
        "    frcnn_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, targets in frcnn_loader:\n",
        "            images = images.to(device)\n",
        "            targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, torch.stack([t['labels'] for t in targets]))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Évaluation simplifiée\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images.to(device))\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels.to(device)).sum().item()\n",
        "\n",
        "        acc = correct / len(test_dataset)\n",
        "        print(f'Epoch {epoch+1}: Loss {total_loss/len(frcnn_loader):.4f}, Acc: {acc:.4f}, Time: {time.time()-start_time:.2f}s')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Exécution\n",
        "frcnn_model = train_frcnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKKNI2tOfx5L",
        "outputId": "29ef5de2-76d8-4016-b612-08e93d4a57de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss 0.1305, Acc: 0.9805, Time: 20.27s\n",
            "Epoch 2: Loss 0.0454, Acc: 0.9874, Time: 20.70s\n",
            "Epoch 3: Loss 0.0299, Acc: 0.9891, Time: 20.71s\n",
            "Epoch 4: Loss 0.0231, Acc: 0.9884, Time: 20.57s\n",
            "Epoch 5: Loss 0.0173, Acc: 0.9897, Time: 20.27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(cnn_model, frcnn_model):\n",
        "    # Fonction d'évaluation commune\n",
        "    def evaluate(model, loader):\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in loader:\n",
        "                outputs = model(images.to(device))\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(labels.cpu().numpy())\n",
        "        return {\n",
        "            'accuracy': accuracy_score(all_targets, all_preds),\n",
        "            'f1': f1_score(all_targets, all_preds, average='macro')\n",
        "        }\n",
        "\n",
        "    # Mesure du temps d'inférence\n",
        "    def benchmark(model, loader):\n",
        "        model.eval()\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for images, _ in loader:\n",
        "                _ = model(images.to(device))\n",
        "        return (time.time() - start) / len(loader.dataset)\n",
        "\n",
        "    # Évaluation\n",
        "    cnn_metrics = evaluate(cnn_model, test_loader)\n",
        "    frcnn_metrics = evaluate(frcnn_model, test_loader)\n",
        "\n",
        "    # Benchmark\n",
        "    cnn_time = benchmark(cnn_model, test_loader)\n",
        "    frcnn_time = benchmark(frcnn_model, test_loader)\n",
        "\n",
        "    # Affichage\n",
        "    print(\"\\nComparaison détaillée:\")\n",
        "    print(f\"{'Metric':<15}{'CNN':<15}{'MiniFasterRCNN':<15}\")\n",
        "    print(f\"{'Accuracy':<15}{cnn_metrics['accuracy']:<15.4f}{frcnn_metrics['accuracy']:<15.4f}\")\n",
        "    print(f\"{'F1 Score':<15}{cnn_metrics['f1']:<15.4f}{frcnn_metrics['f1']:<15.4f}\")\n",
        "    print(f\"{'Inference Time':<15}{cnn_time:<15.6f}{frcnn_time:<15.6f}\")\n",
        "\n",
        "# Exécution\n",
        "compare_models(cnn_model, frcnn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE1366e5r1Pb",
        "outputId": "4f50f209-79f6-4292-aea7-4ebf8fe35d27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparaison détaillée:\n",
            "Metric         CNN            MiniFasterRCNN \n",
            "Accuracy       0.9927         0.9897         \n",
            "F1 Score       0.9926         0.9896         \n",
            "Inference Time 0.000356       0.000226       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n"
      ],
      "metadata": {
        "id": "HuCNYC-UsgSq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convertir MNIST en RGB (3 canaux)\n",
        "    transforms.Resize((224, 224)),  # Adapter aux modèles pré-entraînés\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n",
        "])\n",
        "\n",
        "# Chargement des datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Chargement des données\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Vérification du device (GPU si dispo)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Utilisation de :\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHkCvaGCs30K",
        "outputId": "a2cd4ad4-5166-4231-f3c7-4e90cfc2fd08"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilisation de : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialisation du modèle\n",
        "cnn_model = SimpleCNN().to(device)\n"
      ],
      "metadata": {
        "id": "CE4DXe9PtPmF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=3):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = correct / total\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader):.4f} - Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    train_time = time.time() - start_time\n",
        "    print(f'Training Time: {train_time:.2f}s')\n",
        "\n",
        "    return train_time\n"
      ],
      "metadata": {
        "id": "aj4Oxew4tV8R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_time = train_model(cnn_model, train_loader, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6MFAtTAt3ON",
        "outputId": "e68f7a64-530e-4c39-e57a-446fa19d2b0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 0.2026 - Acc: 0.9472\n",
            "Epoch 2/3 - Loss: 0.0460 - Acc: 0.9858\n",
            "Epoch 3/3 - Loss: 0.0253 - Acc: 0.9912\n",
            "Training Time: 548.61s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(model_name, num_epochs=3):\n",
        "    if model_name == 'vgg16':\n",
        "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "        model.classifier[6] = nn.Linear(4096, 10)\n",
        "    elif model_name == 'alexnet':\n",
        "        model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "        model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loader_p = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader_p = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader_p:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = correct / total\n",
        "        print(f'{model_name} Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader_p):.4f} - Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    train_time = time.time() - start_time\n",
        "    print(f'{model_name} Training Time: {train_time:.2f}s')\n",
        "\n",
        "    return train_time\n",
        "\n",
        "# Entraînement de VGG16 et AlexNet\n",
        "vgg_time = fine_tune_model('vgg16')\n",
        "alex_time = fine_tune_model('alexnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Gf4Rbdt8DE",
        "outputId": "63eaea15-7735-4942-a805-468166c03c6d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16 Epoch 1/3 - Loss: 0.0772 - Acc: 0.9776\n",
            "vgg16 Epoch 2/3 - Loss: 0.0321 - Acc: 0.9909\n",
            "vgg16 Epoch 3/3 - Loss: 0.0233 - Acc: 0.9932\n",
            "vgg16 Training Time: 2939.66s\n",
            "alexnet Epoch 1/3 - Loss: 0.0802 - Acc: 0.9762\n",
            "alexnet Epoch 2/3 - Loss: 0.0374 - Acc: 0.9898\n",
            "alexnet Epoch 3/3 - Loss: 0.0283 - Acc: 0.9919\n",
            "alexnet Training Time: 507.70s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation des données\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Chargement MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "class EfficientViT(nn.Module):\n",
        "    def __init__(self, image_size=28, patch_size=7, num_classes=10, dim=48, depth=2, heads=3):\n",
        "        super().__init__()\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Patch embedding plus efficace\n",
        "        self.patch_embed = nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Token de classe et position embedding\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "\n",
        "        # Transformer optimisé\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=dim,\n",
        "                nhead=heads,\n",
        "                dim_feedforward=dim*2,\n",
        "                dropout=0.1,\n",
        "                activation='gelu',\n",
        "                batch_first=True,\n",
        "                norm_first=True\n",
        "            ),\n",
        "            num_layers=depth\n",
        "        )\n",
        "\n",
        "        # Tête de classification\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding des patches\n",
        "        x = self.patch_embed(x)  # [B, dim, H', W']\n",
        "        x = x.flatten(2).transpose(1, 2)  # [B, num_patches, dim]\n",
        "\n",
        "        # Ajout du token [CLS]\n",
        "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        # Ajout position embedding\n",
        "        x += self.pos_embed\n",
        "\n",
        "        # Transformer\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Classification\n",
        "        return self.head(x[:, 0])\n",
        "\n",
        "def train_efficient_vit(epochs=5, batch_size=32):\n",
        "    # Initialisation\n",
        "    model = EfficientViT().to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Entraînement\n",
        "    print(f\"\\nTraining EfficientViT for {epochs} epochs...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            # Forward + backward\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Métriques\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_acc = correct / len(train_dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f} - Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Évaluation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    final_acc = correct / len(test_dataset)\n",
        "    train_time = time.time() - start_time\n",
        "    params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "\n",
        "    print(f\"\\nTraining Complete!\")\n",
        "    print(f\"- Final Accuracy: {final_acc:.4f}\")\n",
        "    print(f\"- Training Time: {train_time:.2f}s\")\n",
        "    print(f\"- Parameters: {params:.2f}M\")\n",
        "\n",
        "    return model, final_acc, train_time\n",
        "\n",
        "# Exécution\n",
        "vit_model, vit_acc, vit_time = train_efficient_vit()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR5VPjfM5AUT",
        "outputId": "90764303-55d6-40fe-854e-f7c28c82e92c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training EfficientViT for 5 epochs...\n",
            "Epoch 1/5 - Loss: 0.6868 - Acc: 0.7847\n",
            "Epoch 2/5 - Loss: 0.2952 - Acc: 0.9107\n",
            "Epoch 3/5 - Loss: 0.2315 - Acc: 0.9291\n",
            "Epoch 4/5 - Loss: 0.2053 - Acc: 0.9369\n",
            "Epoch 5/5 - Loss: 0.1899 - Acc: 0.9411\n",
            "\n",
            "Training Complete!\n",
            "- Final Accuracy: 0.9567\n",
            "- Training Time: 131.03s\n",
            "- Parameters: 0.04M\n"
          ]
        }
      ]
    }
  ]
}